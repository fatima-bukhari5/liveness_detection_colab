{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fatima-bukhari5/liveness_detection_colab/blob/main/Liveness_VGG16_Copy1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "27af8f73",
      "metadata": {
        "id": "27af8f73"
      },
      "source": [
        "## Library Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e3311ab",
      "metadata": {
        "id": "2e3311ab"
      },
      "outputs": [],
      "source": [
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import argparse\n",
        "import pickle\n",
        "import cv2\n",
        "import os\n",
        "import keras\n",
        "import itertools\n",
        "import pandas as pd\n",
        "from keras import backend as K\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Activation\n",
        "from keras.models import Model\n",
        "from keras.layers.core import Dense, Flatten\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.metrics import categorical_crossentropy\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from keras.layers.convolutional import *\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from imutils import paths\n",
        "from sklearn.metrics import confusion_matrix\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "73100f8d",
      "metadata": {
        "id": "73100f8d"
      },
      "source": [
        "### Importing Data Sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "31d70324",
      "metadata": {
        "id": "31d70324"
      },
      "outputs": [],
      "source": [
        "INIT_LR = 0.0001\n",
        "BS = 10\n",
        "EPOCHS = 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf7a92e2",
      "metadata": {
        "id": "bf7a92e2"
      },
      "outputs": [],
      "source": [
        "# Paths for the images\n",
        "train_path = '/content/real_and_fake/train'\n",
        "valid_path = '/content/real_and_fake/valid'\n",
        "test_path = '/content/real_and_fake/test'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87e481aa",
      "metadata": {
        "id": "87e481aa"
      },
      "outputs": [],
      "source": [
        "def read_image_data(X,Y):\n",
        "    '''\n",
        "    The following function is to convert the data into numpy array through `data_processing` function and \n",
        "    resize it according vgg16 input size of 224 by 224\n",
        "\n",
        "    Parameters:\n",
        "    X => df['Image paths'] (dataframe column of image paths)\n",
        "    Y => df['Labels'] (dataframe column of image labels)\n",
        "\n",
        "    Returns `data` in the form of numpy array and labels as encoded.\n",
        "    '''\n",
        "    \n",
        "    data =[]\n",
        "    labels = Y\n",
        "    for path in X:\n",
        "        image = cv2.imread(path)\n",
        "        image = cv2.resize(image,(224,224))\n",
        "        data.append(image)\n",
        "    data, labels = data_processing(data, labels)\n",
        "    \n",
        "    print('[INFO] Converting Data into Image form and encoding labels')\n",
        "    return data, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f27e579d",
      "metadata": {
        "id": "f27e579d"
      },
      "outputs": [],
      "source": [
        "def data_organization(img_path):\n",
        "    '''\n",
        "    This function is to organize the data in the form of data frames to have clear understanding \n",
        "    and readability of data w.r.t to its labels\n",
        "\n",
        "    Parameters: \n",
        "    img_path = folder path of images base folder as string\n",
        "\n",
        "    Returns: dataframe with organized image paths and their labels\n",
        "    '''\n",
        "    print(\"Getting labels for images...\")\n",
        "    data = []\n",
        "    labels = []\n",
        "    list_image_path = []\n",
        "    folders_list = os.listdir(img_path)\n",
        "    \n",
        "    # loop over all folders at a time. i.e real and fake\n",
        "    for folder in folders_list:\n",
        "        \n",
        "        # extract the class label from the filename to add into the df\n",
        "    \n",
        "        folder_path = os.path.join(img_path,folder)\n",
        "        images_list = os.listdir(folder_path)\n",
        "        for image_name in images_list:\n",
        "            label = folder\n",
        "            imagePath = os.path.join(folder_path,image_name)\n",
        "            labels.append(label)\n",
        "            list_image_path.append(imagePath)\n",
        "            \n",
        "    image_path_label = {'image_path': list_image_path,'labels':labels}\n",
        "    df_image_path_label = pd.DataFrame(image_path_label)\n",
        "    \n",
        "    print(\"DataFrame Complete....\")\n",
        "    return df_image_path_label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ee6bfb9",
      "metadata": {
        "id": "2ee6bfb9"
      },
      "outputs": [],
      "source": [
        "def data_processing(data,labels):\n",
        "    '''\n",
        "    Data processing to convert images data to numpy along with label encoding\n",
        "    \n",
        "    Parameters:\n",
        "    data -> list of images data\n",
        "    labels -> list of labels\n",
        "    \n",
        "    returns:\n",
        "    data, labels as numpy array of image data and encoded labels\n",
        "    '''\n",
        "    data = np.array(data, dtype=\"float\")\n",
        "    le = LabelEncoder()\n",
        "    labels = le.fit_transform(labels)\n",
        "    labels = to_categorical(labels, 2)\n",
        "    \n",
        "    return data, labels"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a85f96f8",
      "metadata": {
        "id": "a85f96f8"
      },
      "source": [
        "## Build Fine-tuned VGG16 model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f93d681e",
      "metadata": {
        "id": "f93d681e"
      },
      "source": [
        "VGG16 Model was used in an ImageNet competition where thousands of images were classified into different categories. We'll be using this model as a baseline and fine tune it as to our specific requirements. \n",
        "VGG16 in itself is a model that classifies images into a number of classes that are not limited to just two. In our case the output layer requires just two nodes representing two classes as `real` and `fake`. So, we will be tuning the model accordingly. \n",
        "<br>\n",
        "<br>\n",
        "\n",
        "Importing the model will take time as its a file of size almost 17 MB "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c3ab0c0",
      "metadata": {
        "id": "1c3ab0c0"
      },
      "outputs": [],
      "source": [
        "def model_training(train_data, train_labels, val_data, val_labels):\n",
        "    '''\n",
        "    The function is involved with \n",
        "        - data augmentation \n",
        "        - sequential model initialization\n",
        "        - using vgg16 model layers as base layers for the new model.\n",
        "        - compiling the model\n",
        "        - training the model\n",
        "    \n",
        "    returns a trained model file\n",
        "    '''\n",
        "    # construct the training image generator for data augmentation\n",
        "    aug = ImageDataGenerator(rotation_range=20, zoom_range=0.15,\n",
        "        width_shift_range=0.2, height_shift_range=0.2, shear_range=0.15,\n",
        "        horizontal_flip=True, fill_mode=\"nearest\")\n",
        "   \n",
        "    print(\"[INFO] importing VGG16 \")\n",
        "    vgg16_model = keras.applications.vgg16.VGG16(include_top=True)\n",
        "    \n",
        "    # getting a sequential model and freezing the previous\n",
        "    model = Sequential()\n",
        "    for layer in vgg16_model.layers[:-1]:\n",
        "        model.add(layer)\n",
        "    \n",
        "    # After poping the last layer, freeze the previous layers and adding a new dense output layer\n",
        "    for layer in model.layers:\n",
        "        layer.trainable = False\n",
        "    model.add(Dense(2, activation='softmax'))\n",
        "    \n",
        "    # initialize the optimizer and model\n",
        "    print(\"[INFO] compiling model...\")\n",
        "    opt = Adam(lr=INIT_LR)\n",
        "    \n",
        "    model.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
        "    \n",
        "    # train the network\n",
        "    print(\"[INFO] training network for {} epochs...\".format(EPOCHS))\n",
        "    \n",
        "    model.fit(x=aug.flow(train_data, train_labels, batch_size=BS),\n",
        "        validation_data=(val_data, val_labels), validation_steps=5, steps_per_epoch=len(train_data) / BS,\n",
        "        epochs=EPOCHS)\n",
        "    \n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4040f21a",
      "metadata": {
        "id": "4040f21a"
      },
      "outputs": [],
      "source": [
        "def get_predictions(model, df_testing):\n",
        "    '''\n",
        "    Getting predictions w.r.t to the trained model as passed and the training data\n",
        "    \n",
        "    Parameters:\n",
        "    model: trained model\n",
        "    df_testing: data for testing in the form of dataframe\n",
        "    \n",
        "    Returns:\n",
        "    \n",
        "    Predictions as 0 or 1 and true_labels after data processing\n",
        "    '''\n",
        "    \n",
        "    # getting test data in numpy \n",
        "    test_data, true_labels = read_image_data(df_testing['image_path'], df_testing['labels']) \n",
        "    \n",
        "    # gettin predictions against the model\n",
        "    print('[INFO] Getting Predictions')\n",
        "    predictions = model.predict(test_data, steps=1, verbose=0)\n",
        "    predictions_rounded = np.round(predictions)\n",
        "    \n",
        "    return predictions_rounded, true_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "79d86f72",
      "metadata": {
        "id": "79d86f72"
      },
      "outputs": [],
      "source": [
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j],\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd3f2ab5",
      "metadata": {
        "id": "dd3f2ab5"
      },
      "outputs": [],
      "source": [
        "def model_performance(predictions, true_labels):\n",
        "    '''\n",
        "    The model displays a confusion matrix using a previously built confusion matrix function taken from sklearn.\n",
        "    \n",
        "    Parameters:\n",
        "    predictions: previous predictions\n",
        "    true_labels: array of actual labels to be compared\n",
        "    \n",
        "    Result: dislay confusion matrix\n",
        "    '''\n",
        "    print('[INFO] Getting Confusion Matrix')\n",
        "    cm = confusion_matrix(true_labels[:,0], predictions[:,0])\n",
        "    \n",
        "\n",
        "    cm_plot_labels = ['real','fake']\n",
        "    plot_confusion_matrix(cm, cm_plot_labels, title='Confusion Matrix')\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1184c7ab",
      "metadata": {
        "id": "1184c7ab"
      },
      "outputs": [],
      "source": [
        "def main():\n",
        "    '''\n",
        "    calling all functions\n",
        "    '''\n",
        "    \n",
        "    # getting labels to each data set\n",
        "    df_training = data_organization(train_path)\n",
        "    df_validation = data_organization(valid_path)\n",
        "    df_testing = data_organization(test_path)\n",
        "    \n",
        "    # getting train and validation data in numpy \n",
        "    train_data, train_labels = read_image_data(df_training['image_path'], df_training['labels'])\n",
        "    val_data, val_labels = read_image_data(df_validation['image_path'], df_validation['labels'])\n",
        "    \n",
        "    # get the trained model\n",
        "    model = model_training(train_data=train_data, train_labels=train_labels, \n",
        "                           val_data=val_data, val_labels=val_labels)\n",
        "    \n",
        "    # get the results\n",
        "    predictions, true_labels = get_predictions(model = model, df_testing=df_testing)\n",
        "    \n",
        "    #\n",
        "    model_performance(predictions=predictions, true_labels=true_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "653c17be",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 991
        },
        "id": "653c17be",
        "outputId": "d39bbe70-56db-4911-abd0-2fc998aa0f85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Getting labels for images...\n",
            "DataFrame Complete....\n",
            "Getting labels for images...\n",
            "DataFrame Complete....\n",
            "Getting labels for images...\n",
            "DataFrame Complete....\n",
            "[INFO] Converting Data into Image form and encoding labels\n",
            "[INFO] Converting Data into Image form and encoding labels\n",
            "[INFO] importing VGG16 \n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
            "553467904/553467096 [==============================] - 3s 0us/step\n",
            "553476096/553467096 [==============================] - 3s 0us/step\n",
            "[INFO] compiling model...\n",
            "[INFO] training network for 8 epochs...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/8\n",
            "16/16 [==============================] - 17s 291ms/step - loss: 0.9411 - accuracy: 0.5515 - val_loss: 0.7071 - val_accuracy: 0.6444\n",
            "Epoch 2/8\n",
            "16/16 [==============================] - 2s 150ms/step - loss: 0.8005 - accuracy: 0.5818 - val_loss: 0.6011 - val_accuracy: 0.7778\n",
            "Epoch 3/8\n",
            "16/16 [==============================] - 2s 149ms/step - loss: 0.6905 - accuracy: 0.6606 - val_loss: 0.4851 - val_accuracy: 0.8667\n",
            "Epoch 4/8\n",
            "16/16 [==============================] - 2s 150ms/step - loss: 0.6860 - accuracy: 0.7030 - val_loss: 0.4100 - val_accuracy: 0.8889\n",
            "Epoch 5/8\n",
            "16/16 [==============================] - 3s 153ms/step - loss: 0.6184 - accuracy: 0.7515 - val_loss: 0.3620 - val_accuracy: 0.9556\n",
            "Epoch 6/8\n",
            "16/16 [==============================] - 3s 153ms/step - loss: 0.5837 - accuracy: 0.7455 - val_loss: 0.3282 - val_accuracy: 0.9333\n",
            "Epoch 7/8\n",
            "16/16 [==============================] - 3s 153ms/step - loss: 0.5260 - accuracy: 0.7515 - val_loss: 0.3043 - val_accuracy: 0.9333\n",
            "Epoch 8/8\n",
            "16/16 [==============================] - 3s 153ms/step - loss: 0.5388 - accuracy: 0.7455 - val_loss: 0.2886 - val_accuracy: 0.9556\n",
            "[INFO] Converting Data into Image form and encoding labels\n",
            "[INFO] Getting Predictions\n",
            "[INFO] Getting Confusion Matrix\n",
            "Confusion matrix, without normalization\n",
            "[[5 0]\n",
            " [0 5]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "main()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mobile Net"
      ],
      "metadata": {
        "id": "56mbBEMbeZMQ"
      },
      "id": "56mbBEMbeZMQ"
    },
    {
      "cell_type": "code",
      "source": [
        "mobile = keras.applications.mobilenet.MobileNet()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jfj4pPcFedmP",
        "outputId": "bad6939f-d800-491a-dffe-fd3574a7357f"
      },
      "id": "jfj4pPcFedmP",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet/mobilenet_1_0_224_tf.h5\n",
            "17227776/17225924 [==============================] - 0s 0us/step\n",
            "17235968/17225924 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mobile.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJsdM9dQepFx",
        "outputId": "2bc0262d-d1d4-44fd-ea27-dd656f7a9c9e"
      },
      "id": "kJsdM9dQepFx",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"mobilenet_1.00_224\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " conv1 (Conv2D)              (None, 112, 112, 32)      864       \n",
            "                                                                 \n",
            " conv1_bn (BatchNormalizatio  (None, 112, 112, 32)     128       \n",
            " n)                                                              \n",
            "                                                                 \n",
            " conv1_relu (ReLU)           (None, 112, 112, 32)      0         \n",
            "                                                                 \n",
            " conv_dw_1 (DepthwiseConv2D)  (None, 112, 112, 32)     288       \n",
            "                                                                 \n",
            " conv_dw_1_bn (BatchNormaliz  (None, 112, 112, 32)     128       \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_dw_1_relu (ReLU)       (None, 112, 112, 32)      0         \n",
            "                                                                 \n",
            " conv_pw_1 (Conv2D)          (None, 112, 112, 64)      2048      \n",
            "                                                                 \n",
            " conv_pw_1_bn (BatchNormaliz  (None, 112, 112, 64)     256       \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_pw_1_relu (ReLU)       (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " conv_pad_2 (ZeroPadding2D)  (None, 113, 113, 64)      0         \n",
            "                                                                 \n",
            " conv_dw_2 (DepthwiseConv2D)  (None, 56, 56, 64)       576       \n",
            "                                                                 \n",
            " conv_dw_2_bn (BatchNormaliz  (None, 56, 56, 64)       256       \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_dw_2_relu (ReLU)       (None, 56, 56, 64)        0         \n",
            "                                                                 \n",
            " conv_pw_2 (Conv2D)          (None, 56, 56, 128)       8192      \n",
            "                                                                 \n",
            " conv_pw_2_bn (BatchNormaliz  (None, 56, 56, 128)      512       \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_pw_2_relu (ReLU)       (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " conv_dw_3 (DepthwiseConv2D)  (None, 56, 56, 128)      1152      \n",
            "                                                                 \n",
            " conv_dw_3_bn (BatchNormaliz  (None, 56, 56, 128)      512       \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_dw_3_relu (ReLU)       (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " conv_pw_3 (Conv2D)          (None, 56, 56, 128)       16384     \n",
            "                                                                 \n",
            " conv_pw_3_bn (BatchNormaliz  (None, 56, 56, 128)      512       \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_pw_3_relu (ReLU)       (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " conv_pad_4 (ZeroPadding2D)  (None, 57, 57, 128)       0         \n",
            "                                                                 \n",
            " conv_dw_4 (DepthwiseConv2D)  (None, 28, 28, 128)      1152      \n",
            "                                                                 \n",
            " conv_dw_4_bn (BatchNormaliz  (None, 28, 28, 128)      512       \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_dw_4_relu (ReLU)       (None, 28, 28, 128)       0         \n",
            "                                                                 \n",
            " conv_pw_4 (Conv2D)          (None, 28, 28, 256)       32768     \n",
            "                                                                 \n",
            " conv_pw_4_bn (BatchNormaliz  (None, 28, 28, 256)      1024      \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_pw_4_relu (ReLU)       (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " conv_dw_5 (DepthwiseConv2D)  (None, 28, 28, 256)      2304      \n",
            "                                                                 \n",
            " conv_dw_5_bn (BatchNormaliz  (None, 28, 28, 256)      1024      \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_dw_5_relu (ReLU)       (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " conv_pw_5 (Conv2D)          (None, 28, 28, 256)       65536     \n",
            "                                                                 \n",
            " conv_pw_5_bn (BatchNormaliz  (None, 28, 28, 256)      1024      \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_pw_5_relu (ReLU)       (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " conv_pad_6 (ZeroPadding2D)  (None, 29, 29, 256)       0         \n",
            "                                                                 \n",
            " conv_dw_6 (DepthwiseConv2D)  (None, 14, 14, 256)      2304      \n",
            "                                                                 \n",
            " conv_dw_6_bn (BatchNormaliz  (None, 14, 14, 256)      1024      \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_dw_6_relu (ReLU)       (None, 14, 14, 256)       0         \n",
            "                                                                 \n",
            " conv_pw_6 (Conv2D)          (None, 14, 14, 512)       131072    \n",
            "                                                                 \n",
            " conv_pw_6_bn (BatchNormaliz  (None, 14, 14, 512)      2048      \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_pw_6_relu (ReLU)       (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " conv_dw_7 (DepthwiseConv2D)  (None, 14, 14, 512)      4608      \n",
            "                                                                 \n",
            " conv_dw_7_bn (BatchNormaliz  (None, 14, 14, 512)      2048      \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_dw_7_relu (ReLU)       (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " conv_pw_7 (Conv2D)          (None, 14, 14, 512)       262144    \n",
            "                                                                 \n",
            " conv_pw_7_bn (BatchNormaliz  (None, 14, 14, 512)      2048      \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_pw_7_relu (ReLU)       (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " conv_dw_8 (DepthwiseConv2D)  (None, 14, 14, 512)      4608      \n",
            "                                                                 \n",
            " conv_dw_8_bn (BatchNormaliz  (None, 14, 14, 512)      2048      \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_dw_8_relu (ReLU)       (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " conv_pw_8 (Conv2D)          (None, 14, 14, 512)       262144    \n",
            "                                                                 \n",
            " conv_pw_8_bn (BatchNormaliz  (None, 14, 14, 512)      2048      \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_pw_8_relu (ReLU)       (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " conv_dw_9 (DepthwiseConv2D)  (None, 14, 14, 512)      4608      \n",
            "                                                                 \n",
            " conv_dw_9_bn (BatchNormaliz  (None, 14, 14, 512)      2048      \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_dw_9_relu (ReLU)       (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " conv_pw_9 (Conv2D)          (None, 14, 14, 512)       262144    \n",
            "                                                                 \n",
            " conv_pw_9_bn (BatchNormaliz  (None, 14, 14, 512)      2048      \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_pw_9_relu (ReLU)       (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " conv_dw_10 (DepthwiseConv2D  (None, 14, 14, 512)      4608      \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv_dw_10_bn (BatchNormali  (None, 14, 14, 512)      2048      \n",
            " zation)                                                         \n",
            "                                                                 \n",
            " conv_dw_10_relu (ReLU)      (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " conv_pw_10 (Conv2D)         (None, 14, 14, 512)       262144    \n",
            "                                                                 \n",
            " conv_pw_10_bn (BatchNormali  (None, 14, 14, 512)      2048      \n",
            " zation)                                                         \n",
            "                                                                 \n",
            " conv_pw_10_relu (ReLU)      (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " conv_dw_11 (DepthwiseConv2D  (None, 14, 14, 512)      4608      \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv_dw_11_bn (BatchNormali  (None, 14, 14, 512)      2048      \n",
            " zation)                                                         \n",
            "                                                                 \n",
            " conv_dw_11_relu (ReLU)      (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " conv_pw_11 (Conv2D)         (None, 14, 14, 512)       262144    \n",
            "                                                                 \n",
            " conv_pw_11_bn (BatchNormali  (None, 14, 14, 512)      2048      \n",
            " zation)                                                         \n",
            "                                                                 \n",
            " conv_pw_11_relu (ReLU)      (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " conv_pad_12 (ZeroPadding2D)  (None, 15, 15, 512)      0         \n",
            "                                                                 \n",
            " conv_dw_12 (DepthwiseConv2D  (None, 7, 7, 512)        4608      \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv_dw_12_bn (BatchNormali  (None, 7, 7, 512)        2048      \n",
            " zation)                                                         \n",
            "                                                                 \n",
            " conv_dw_12_relu (ReLU)      (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            " conv_pw_12 (Conv2D)         (None, 7, 7, 1024)        524288    \n",
            "                                                                 \n",
            " conv_pw_12_bn (BatchNormali  (None, 7, 7, 1024)       4096      \n",
            " zation)                                                         \n",
            "                                                                 \n",
            " conv_pw_12_relu (ReLU)      (None, 7, 7, 1024)        0         \n",
            "                                                                 \n",
            " conv_dw_13 (DepthwiseConv2D  (None, 7, 7, 1024)       9216      \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv_dw_13_bn (BatchNormali  (None, 7, 7, 1024)       4096      \n",
            " zation)                                                         \n",
            "                                                                 \n",
            " conv_dw_13_relu (ReLU)      (None, 7, 7, 1024)        0         \n",
            "                                                                 \n",
            " conv_pw_13 (Conv2D)         (None, 7, 7, 1024)        1048576   \n",
            "                                                                 \n",
            " conv_pw_13_bn (BatchNormali  (None, 7, 7, 1024)       4096      \n",
            " zation)                                                         \n",
            "                                                                 \n",
            " conv_pw_13_relu (ReLU)      (None, 7, 7, 1024)        0         \n",
            "                                                                 \n",
            " global_average_pooling2d (G  (None, 1, 1, 1024)       0         \n",
            " lobalAveragePooling2D)                                          \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1, 1, 1024)        0         \n",
            "                                                                 \n",
            " conv_preds (Conv2D)         (None, 1, 1, 1000)        1025000   \n",
            "                                                                 \n",
            " reshape_2 (Reshape)         (None, 1000)              0         \n",
            "                                                                 \n",
            " predictions (Activation)    (None, 1000)              0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,253,864\n",
            "Trainable params: 4,231,976\n",
            "Non-trainable params: 21,888\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "TINkijlaey8q"
      },
      "id": "TINkijlaey8q",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "name": "Liveness VGG16-Copy1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}